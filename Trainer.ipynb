{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c351b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import mmap\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d65f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "block_size = 128\n",
    "max_iters = 10000\n",
    "learning_rate = 2e-5\n",
    "eval_iters = 100\n",
    "n_embd = 384\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46d70086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import Data_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a936ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import GPTLanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30d2b8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size,train,test=Data_preprocess.loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86688912",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_object = GPTLanguageModel(vocab_size)\n",
    "\n",
    "m = model_object.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4a0918",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    model_object.eval()\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for _ in range(eval_iters):\n",
    "            xb_train, yb_train = Data_preprocess.get_batch(train)\n",
    "            _, loss = model_object(xb_train, yb_train)\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            xb_val, yb_val = Data_preprocess.get_batch(test)\n",
    "            _, val_loss_batch = model_object(xb_val, yb_val)\n",
    "            val_loss += val_loss_batch.item()\n",
    "    model_object.train()\n",
    "    return {\"train\": train_loss / eval_iters, \"val\": val_loss / eval_iters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36a1c38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train loss: 1.194, val loss: 1.439\n",
      "step: 100, train loss: 1.194, val loss: 1.438\n",
      "step: 200, train loss: 1.190, val loss: 1.434\n",
      "step: 300, train loss: 1.188, val loss: 1.434\n",
      "step: 400, train loss: 1.187, val loss: 1.434\n",
      "step: 500, train loss: 1.182, val loss: 1.441\n",
      "step: 600, train loss: 1.183, val loss: 1.438\n",
      "step: 700, train loss: 1.182, val loss: 1.433\n",
      "step: 800, train loss: 1.181, val loss: 1.437\n",
      "step: 900, train loss: 1.178, val loss: 1.435\n",
      "step: 1000, train loss: 1.179, val loss: 1.434\n",
      "step: 1100, train loss: 1.177, val loss: 1.432\n",
      "step: 1200, train loss: 1.175, val loss: 1.437\n",
      "step: 1300, train loss: 1.177, val loss: 1.431\n",
      "step: 1400, train loss: 1.172, val loss: 1.428\n",
      "step: 1500, train loss: 1.167, val loss: 1.434\n",
      "step: 1600, train loss: 1.168, val loss: 1.438\n",
      "step: 1700, train loss: 1.168, val loss: 1.442\n",
      "step: 1800, train loss: 1.171, val loss: 1.434\n",
      "step: 1900, train loss: 1.159, val loss: 1.434\n",
      "step: 2000, train loss: 1.165, val loss: 1.433\n",
      "step: 2100, train loss: 1.160, val loss: 1.432\n",
      "step: 2200, train loss: 1.156, val loss: 1.440\n",
      "step: 2300, train loss: 1.164, val loss: 1.433\n",
      "step: 2400, train loss: 1.160, val loss: 1.434\n",
      "step: 2500, train loss: 1.156, val loss: 1.424\n",
      "step: 2600, train loss: 1.159, val loss: 1.430\n",
      "step: 2700, train loss: 1.152, val loss: 1.428\n",
      "step: 2800, train loss: 1.157, val loss: 1.431\n",
      "step: 2900, train loss: 1.154, val loss: 1.432\n",
      "step: 3000, train loss: 1.158, val loss: 1.425\n",
      "step: 3100, train loss: 1.149, val loss: 1.430\n",
      "step: 3200, train loss: 1.151, val loss: 1.423\n",
      "step: 3300, train loss: 1.144, val loss: 1.436\n",
      "step: 3400, train loss: 1.143, val loss: 1.430\n",
      "step: 3500, train loss: 1.142, val loss: 1.429\n",
      "step: 3600, train loss: 1.145, val loss: 1.424\n",
      "step: 3700, train loss: 1.143, val loss: 1.425\n",
      "step: 3800, train loss: 1.136, val loss: 1.423\n",
      "step: 3900, train loss: 1.136, val loss: 1.421\n",
      "step: 4000, train loss: 1.138, val loss: 1.426\n",
      "step: 4100, train loss: 1.136, val loss: 1.428\n",
      "step: 4200, train loss: 1.134, val loss: 1.423\n",
      "step: 4300, train loss: 1.133, val loss: 1.421\n",
      "step: 4400, train loss: 1.137, val loss: 1.419\n",
      "step: 4500, train loss: 1.131, val loss: 1.425\n",
      "step: 4600, train loss: 1.130, val loss: 1.423\n",
      "step: 4700, train loss: 1.126, val loss: 1.417\n",
      "step: 4800, train loss: 1.129, val loss: 1.419\n",
      "step: 4900, train loss: 1.124, val loss: 1.427\n",
      "step: 5000, train loss: 1.122, val loss: 1.417\n",
      "step: 5100, train loss: 1.121, val loss: 1.422\n",
      "step: 5200, train loss: 1.122, val loss: 1.429\n",
      "step: 5300, train loss: 1.122, val loss: 1.423\n",
      "step: 5400, train loss: 1.114, val loss: 1.415\n",
      "step: 5500, train loss: 1.126, val loss: 1.412\n",
      "step: 5600, train loss: 1.121, val loss: 1.414\n",
      "step: 5700, train loss: 1.117, val loss: 1.426\n",
      "step: 5800, train loss: 1.119, val loss: 1.422\n",
      "step: 5900, train loss: 1.119, val loss: 1.414\n",
      "step: 6000, train loss: 1.117, val loss: 1.422\n",
      "step: 6100, train loss: 1.112, val loss: 1.415\n",
      "step: 6200, train loss: 1.112, val loss: 1.419\n",
      "step: 6300, train loss: 1.114, val loss: 1.411\n",
      "step: 6400, train loss: 1.111, val loss: 1.411\n",
      "step: 6500, train loss: 1.107, val loss: 1.419\n",
      "step: 6600, train loss: 1.107, val loss: 1.420\n",
      "step: 6700, train loss: 1.105, val loss: 1.428\n",
      "step: 6800, train loss: 1.104, val loss: 1.408\n",
      "step: 6900, train loss: 1.102, val loss: 1.410\n",
      "step: 7000, train loss: 1.102, val loss: 1.411\n",
      "step: 7100, train loss: 1.101, val loss: 1.415\n",
      "step: 7200, train loss: 1.099, val loss: 1.421\n",
      "step: 7300, train loss: 1.101, val loss: 1.414\n",
      "step: 7400, train loss: 1.099, val loss: 1.419\n",
      "step: 7500, train loss: 1.095, val loss: 1.418\n",
      "step: 7600, train loss: 1.094, val loss: 1.404\n",
      "step: 7700, train loss: 1.092, val loss: 1.408\n",
      "step: 7800, train loss: 1.096, val loss: 1.407\n",
      "step: 7900, train loss: 1.088, val loss: 1.419\n",
      "step: 8000, train loss: 1.088, val loss: 1.418\n",
      "step: 8100, train loss: 1.086, val loss: 1.418\n",
      "step: 8200, train loss: 1.086, val loss: 1.415\n",
      "step: 8300, train loss: 1.083, val loss: 1.416\n",
      "step: 8400, train loss: 1.079, val loss: 1.418\n",
      "step: 8500, train loss: 1.082, val loss: 1.411\n",
      "step: 8600, train loss: 1.082, val loss: 1.410\n",
      "step: 8700, train loss: 1.080, val loss: 1.403\n",
      "step: 8800, train loss: 1.076, val loss: 1.410\n",
      "step: 8900, train loss: 1.078, val loss: 1.412\n",
      "step: 9000, train loss: 1.079, val loss: 1.415\n",
      "step: 9100, train loss: 1.073, val loss: 1.412\n",
      "step: 9200, train loss: 1.074, val loss: 1.411\n",
      "step: 9300, train loss: 1.074, val loss: 1.413\n",
      "step: 9400, train loss: 1.074, val loss: 1.418\n",
      "step: 9500, train loss: 1.073, val loss: 1.414\n",
      "step: 9600, train loss: 1.073, val loss: 1.405\n",
      "step: 9700, train loss: 1.071, val loss: 1.413\n",
      "step: 9800, train loss: 1.070, val loss: 1.407\n",
      "step: 9900, train loss: 1.064, val loss: 1.409\n",
      "1.1573641300201416\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model_object.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"Step: {iter}, Train Loss: {losses['train']:.3f}, Val Loss: {losses['val']:.3f}\")\n",
    "    \n",
    "\n",
    "    xb, yb = Data_preprocess.get_batch(train)\n",
    "\n",
    "\n",
    "    logits, loss = model_object(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f\"Final Loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "with open('trial_3_10000iter.pkl', 'wb') as f:\n",
    "    pickle.dump(model_object, f)\n",
    "print('Model saved as trial_3_10000iter.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
